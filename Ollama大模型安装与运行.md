近来，不少朋友在互联网上求助关于如何在Ubuntu操作系统中安装Ollama的问题。今天，我就来为大家带来一篇详尽的指南，教你在Ubuntu Server 24.04上安装最新的Ollama版本，并成功下载与运行大型模型。

首先，让我们前往Ubuntu官方下载页面：

Get Ubuntu Server | Download | Ubuntu

图片

点击“下载24.04.1 LTS”，下载对应的ISO镜像文件。Ubuntu官网提供了详尽的安装教程，包括如何使用U盘安装、在虚拟机中部署以及制作启动盘等步骤。
如果需要更详细的指导，请访问：Basic installation | Ubuntu
 接下来，前往Ollama的官方网站：Ollama
图片

点击“Download"按钮，选择Linux平台的安装包。
使用以下命令在终端中安装Ollama：
curl -fsSL https://ollama.com/install.sh | sh
在安装过程中，系统会要求你输入root用户的密码。安装完成后，你会看到如下提示：
[sudo] password for fengshuai:
图片

需要注意的是，由于我的机器没有独立显卡，Ollama 只能使用CPU模式运行。我们会在后面的部分继续探讨这个问题。

图片

验证安装版本是否为最新版（撰写此文时，最新版本号为0.3.11），可以使用命令：

ollama -v
图片

键入 ollama 查看可用命令：

ollama
图片

对于初学者来说，run 和 list 是最常用的命令，其他的命令可以通过在线搜索了解其功能。

现在，我们已经完成了Ollama的基本安装，下一步是学习如何安装大型模型。

返回Ollama的主页，点击“Models”标签：

图片

浏览不同的模型，选择你感兴趣的那个，例如：qwen2.5。

图片

点击该模型后，你会看到参数选择页面。在这里，根据电脑配置可以自己选择，我考虑性能问题，选择1.5B参数。需要注意的是，并不需要具备高性能显卡来运行这些模型；即便是普通办公电脑也能胜任这项任务。

图片

重要提示：确保Ubuntu有足够的虚拟内存空间，否则某些模型可能会遇到错误。如果你的硬件配置较高，这个问题就不用担心了。

复制安装页面给出的命令：
ollama run qwen2.5:1.5b
根据所选模型的大小，等待下载完成。下载结束后，系统将直接进入交互界面：

图片

图片

至此，所有的准备工作都已完成，你现在可以尽情探索各种大型模型的研究应用了！
